# Description: Configuration file for PPO algorithm
PPO:
    exp_name: ppo_caps_nova
    seed: ???
    torch_deterministic: True
    cuda: True
    track: True # enable wandb tracking
    wandb_project_name: 'uav_rl'
    wandb_entity: thesedavid
    capture_video: False # not working, legacy of cleanRL's implementation

    # model
    input_arch: 'mlp' # 'cnn' or 'mlp'

    # eval while training
    periodic_eval: True
    eval_freq: 37_500
    final_eval: False # evaluate the agent at the end of training
    final_traj_plot: True # plot an evaluation plot at the end of training
    save_best: False # save the best model
    save_cp: False # save periodic checkpoints

    # CleanRL's PPO algo args
    total_timesteps: 750_000
    env_id: 'ACBohnNoVaIErr-v0'
    learning_rate: 3e-4
    num_envs: 6 # number of parallel environments
    num_steps: 2048 # num of steps to run in each env per policy rollout
    anneal_lr: True # anneal the learning rate
    gamma: 0.99 # discount factor
    gae_lambda: 0.95 # GAE lambda
    num_minibatches: 32 # number of minibatches to train the policy on
    batch_size: ${eval:'${PPO.num_envs} * ${PPO.num_steps}'}
    minibatch_size: ${eval:'${PPO.batch_size} // ${PPO.num_minibatches}'} # minibatch size
    update_epochs: 10 # number of epochs to train the policy on
    norm_adv: True # normalize the advantage
    clip_coef: 0.2 # surrogate clipping coefficient
    clip_vloss: True # clip the value loss
    ent_coef: 0.01 # entropy coefficient
    vf_coef: 0.5 # value function coefficient
    max_grad_norm: 0.5 # max gradient norm for gradient clipping
    target_kl: null # target KL divergence threshold

    # Personnal customizations to the algo
    ts_coef: 5e-2 # CAPS temporal smoothing coefficient
    ss_coef: 0.0 # CAPS spatial smoothing coefficient
    pa_coef: 0.0 # Pre activation coefficient (only in Bohn n2 paper)
    rand_targets: True # randomly sample references
    ref_sampler: 'uniform' # reference sampling distrib for the UAV
    cst_beta: null # if ref_sampler is 'beta', set a constant beta.

